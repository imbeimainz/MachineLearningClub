---
title: "An Introduction to Statistical Learning - with applications in R"
subtitle: "Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani"
author: "Irene Schmidtmann (Irene.Schmidtmann@uni-mainz.de)</br>"
date: "2020/03/09</br>
  IMBEI - University Medical Center Mainz"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts","css/FMstyles.css","css/animate.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [center, middle]
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  eval = TRUE,
  message = FALSE,
  echo = TRUE,
  warnings = TRUE,
  fig.align = "center"
)
```


```{r setup2, include=FALSE}
library(ISLR)
library(readr)
library(lattice)
library(knitr)

# import Income data (downloaded from http://faculty.marshall.usc.edu/gareth-james/ISL/data.html)
Advertising <- read_csv("~/GitHub/IMBEIbookclub/Introduction to Statistical Learning - 2020/chapter2-statistical_learning/chapter2_files/Advertising.csv")
Income1 <- read_csv("~/GitHub/IMBEIbookclub/Introduction to Statistical Learning - 2020/chapter2-statistical_learning/chapter2_files/Income1.csv")
Income2 <- read_csv("~/GitHub/IMBEIbookclub/Introduction to Statistical Learning - 2020/chapter2-statistical_learning/chapter2_files/Income2.csv")
```

class: inverse, center, middle

# Chapter 2:  Statistical Learning

---
# Structure of chapter 2
Chapter gives an overview, presents concepts and definitions.

2.1  What Is Statistical Learning?

2.2 Assessing Model Accuracy

2.3  Lab: Introduction to R (will be covered next week)

---
#2.1  What Is Statistical Learning?

Motivating example: company wants to increase sales of a product.
* not possible directly
* but advertising expenditure can be controlled
* three advertising channels
  + TV
  + Radio
  + Newspapers
  
So there we have
* *output variable* we want to predict
  + $Y$ Sales
  + other terms: *response*, *dependent variable*
* *input variables* we can control 
  + $X_1$ TV budget
  + $X_2$ Radio budget
  + $X_3$ Newspapers budget
  + other terms: *predictors*, *independent variables*, *features*

---
#2.1  What Is Statistical Learning?
General aim: find a function $f$ that allows to predict $Y$ given $X_1, \ldots, X_p$
$$Y = f(X) + \epsilon$$
with

$f$ fixed but unknown function of $X_1, \ldots, X_p$

$\epsilon$ *random error* term, independent of $X$ with mean zero

$f$ represents *systematic information* on $Y$ provided by $X$

## Essence
* Statistical learning 
  + set of approaches for estimating $f$ 
* This chapter outlines
  + key theoretical concepts that arise in estimating $f$
  + tools for evaluating the estimates obtained

---
#Example 1: Advertising data
## Data: sales and advertising budgets in 200 markets
```{r advertise_1, echo=TRUE}
attach(Advertising)
head(Advertising)
```

---
# How are sales related to advertising?

```{r advertise_2a, echo=FALSE, eval=TRUE, fig.height = 6, fig.width = 12, fig.cap = "Fig 2.1 Sales as function of TV, radio, and newspaper budget (in 1000's of $). Simple least squares fit", fig.align = "left"}
par(mfcol=c(1,3))

plot(x = TV, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
TV.reg <-lm(sales ~ TV, data = Advertising)
abline(coef = TV.reg$coefficients, col="blue",lwd=2)

plot(x = radio, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
radio.reg <-lm(sales ~ radio, data = Advertising)
abline(coef = radio.reg$coefficients, col="blue",lwd=2)

plot(x = newspaper, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
newspaper.reg <-lm(sales ~ newspaper, data = Advertising)
abline(coef = newspaper.reg$coefficients, col="blue",lwd=2)
```

---
# How are sales related to advertising?

```{r advertise_2b, echo=TRUE, eval=FALSE, fig.height = 6, fig.width = 12}
par(mfcol=c(1,3))

plot(x = TV, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
TV.reg <-lm(sales ~ TV, data = Advertising)
abline(coef = TV.reg$coefficients, col="blue",lwd=2)

plot(x = radio, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
radio.reg <-lm(sales ~ radio, data = Advertising)
abline(coef = radio.reg$coefficients, col="blue",lwd=2)

plot(x = newspaper, y = sales, col="red", 
     cex=1.5, cex.lab=1.5, cex.axis = 1.5)
newspaper.reg <-lm(sales ~ newspaper, data = Advertising)
abline(coef = newspaper.reg$coefficients, col="blue",lwd=2)
```

```{r Detach_Avertising, echo = FALSE, include = FALSE}
detach(Advertising)
```

---
#Example 2: Income
## Data: Income, education and seniority
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.3.png")
```
Fig 2.3 Income, education and seniority (true underlying function and simulated data are shown)

---
# 2.1.1 Why estimate f?
## Prediction
* Input $X$ is easily obtained
* Output $Y$ is difficult to obtain
* Therefore: predict $Y$ using $\hat{Y} = \hat{f}(X)$
  + $\hat{f}$ *estimate* for f
  + $\hat{Y}$ resulting *prediction* for $Y$
  + $f$ as "black box" -- little interest in specific form if predictions is accurate

---
## Prediction: Types of error  
* *reducible error*
  + improvement by using best statistical learning technique
  + "systematic error"
* *irreducible error*
  + cannot be overcome because of unknown $\epsilon$
  + "random error"
  
$$\begin{aligned}
E(Y-\hat{Y})^{2} &=E[f(X)+\epsilon-\hat{f}(X)]^{2} \\
&=\underbrace{[f(X)-\hat{f}(X)]^{2}}_{\text {Reducible }}+\underbrace{\operatorname{Var}(\epsilon)}_{\text {Irreducible }}
\end{aligned}$$

---
# 2.1.1 Why estimate f?
## Inference  
* Understand relationship between predictors and response
* Which predictors are important?
* Is a simple linear relationship adequate?

## Prediction or inference?
* Distinction between prediction and inference not always clear-cut
* Researchers might be interested in both
* Trade-Off between 
  + accurate prediction (often more complicated models) and 
  + interpretability (simpler models)

---
# 2.1.2 How do we estimate f?
## Typical strategy: 
* Use *training data* to train/teach method how to estimate $f$. 
* Training data set typically consists of $n$ data points: $\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{n}, y_{n}\right)\right\}$
* Goal: apply a statistical learning method to the training data in order to estimate the unknown function $f$.

---
# 2.1.2 How do we estimate f?
## Parametric methods
Model based
1. Make assumption about functional form, e. g. linear model, i. e. linear in parameters
$$f(X)=\beta_{0}+\beta_{1} X_{1}+\beta_{2} X_{2}+\ldots+\beta_{p} X_{p}$$
2. Estimate parameters $\beta_{0}, \beta_{1}, \dots, \beta_{p}$, e. g. by least squares, such that $$Y \approx \beta_{0}+\beta_{1} X_{1}+\beta_{2} X_{2}+\ldots+\beta_{p} X_{p}$$
 

* Advantage
  + Simplicity
* Disadvantage
  + will usually not match the true unknown form
  + poor fit if true form is very different
* More flexible models
  + more parameters
  + overfitting as model follows "noise" in the data

---
## Example: fit linear model to income data
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.4.png")
```
Fig 2.4 Income, education and seniority. Linear model fit by least squares:
$$\text { income } \approx \beta_{0}+\beta_{1} \times \text { education }+\beta_{2} \times \text { seniority }$$ Model captures main trend, but misses curvature.

---
# 2.1.2 How do we estimate f?
## Non-parametric methods
* No explicit assumption about form of function
* Seek estimate 
  + close to the data point
  + not too wiggly
  + not too rough
* Advantage
  + wider rang of shapes is possible
* Disadvantage
  + large sample size needed for accurate estimate of $f$

---
## Example: fit thin-plate spline to income data
* Splines
  + piecewise polynomials, often of degree 3
  + "glue" pieces together at interval boundaries
  + ensure smooth transition at boundaries by conditions on derivatives
* Thin-plate splines have a built-in penalty to obtain a function
  + that closely approximates observations
  + is fairly smooth
  + minimizes 
  
$\sum_{i=1}^{K}\left\|y_{i}-f\left(x_{i}\right)\right\|^{2}+\lambda \iint\left[\left(\frac{\partial^{2} f}{\partial x_{1}^{2}}\right)^{2}+2\left(\frac{\partial^{2} f}{\partial x_{1} \partial x_{2}}\right)^{2}+\left(\frac{\partial^{2} f}{\partial x_{2}^{2}}\right)^{2}\right] \mathrm{d} x_{1} \mathrm{d} x_{2}$
  + tuning parameter $\lambda$ determines relative importance of smoothness and closeness to observed data
* More about splines in chapter 7.

---
## Example: fit smooth thin-plate spline to income data
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.5.png")
```
Fig 2.5 Income, education and seniority. A smooth thin-plate spline fit to the income data. 

---
## Example: fit smooth thin-plate spline to income data
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.6.png")
```
Fig 2.6 Income, education and seniority. A rough thin-plate spline fit to the income data, $\lambda \approx 0$. 

* No error on the training data, but more variability.
* Probably overfitting, too much noise incorporated.

---
# 2.1.3 The trade-off between prediction accuracy and model interpretability
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 140}
include_graphics(path = "images/fig 2.7.png")
```
Fig 2.7 Trade-off between flexibility and interpretability, using different statistical learning methods. 

---
# 2.1.4 Supervised versus unsupervised learning
* Examples so far: supervised learning
  + Predictors *and* response were given.
* Unsupervised learning
  + For every observation there is a vector of measurements $x_i$, but no associated response. $\Rightarrow$ Impossibility to fit linear regression model
  + Seek to understand relationships between variables or between observations.
  + Typical method: cluster analysis - do observations fall in distinct groups?
  
---
## Example 3: cluster analysis
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 100}
include_graphics(path = "images/fig 2.8.png")
```
Fig 2.8 Clustering data set involving three groups. Groups denoted by different colored symbols. Left: The three groups are well-separated. In this setting, a clustering approach should successfully identify the three groups. Right: There is some overlap among the groups. Now the clustering task is more challenging.

Here: hidden group structure assumed.

---
# 2.1.5 Regression versus classification problems
* Problems with *quantitative* response referred to as *regression problems*
* Problems with *qualitative* response referred to as *classification problems*
* Distinction not always clear-cut
  + Logistic regression used with qualitative data 
  + Logistic regression often serves as classification method
  + K-nearest neighbours and boosting can be used with both quantitative and qualitative data.
* Choice of methods based on type of response
* Type of predictors can be both, provided they are suitably coded.

---
# 2.2 Assessing model accuracy
* No method is uniformly best
* Selecting best approach most challenging part of statistical learning in practice

## 2.2.1 Measuring quality of fit
Most commonly used measure: mean square error
$$M S E=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{f}\left(x_{i}\right)\right)^{2}$$
with $\hat{f}\left(x_{i}\right)$ prediction that $\hat{f}$ fives for $i$-th observation

* Cave: this refers to the *training data*.
* However, interest is in the $MSE$ for *test data*, i. e. future data not involved in obtaining the model
* How to achieve this?
  + Sometimes test data is available.
  + Minimizing $MSE$ may result in serious overfitting.

---
## Some examples comparing training and test MSE
### Example 4:
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.9.png")
```
Fig 2.9 Left: Data simulated from f, shown in black. Three estimates of
f are shown: the linear regression line (orange curve), and two smoothing spline
fits (blue and green curves). Right: Training MSE (grey curve), test MSE (red
curve), and minimum possible test MSE over all methods (dashed line). Squares
represent the training and test MSEs for the three fits shown in the left-hand
panel.
---
### Example 5:
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.10.png")
```
Fig 2.10 Details as in Figure 2.9, different true f that is much closer to linear. Here: linear regression provides a very good fit to the data.

---
### Example 6:
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.11.png")
```
Fig 2.11 Details as in Figure 2.9, different true f that is far from linear. Here: linear regression provides a very poor fit to the data.

---
### Summary of bias and variance from examples
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.12.png")
```
Fig 2.12 Squared bias (blue), variance (orange), $Var(\epsilon)$ (dashed line), and test $MSE$ (red) for the three data sets in Figures 2.9â€“2.11. Vertical dotted line indicates the flexibility level corresponding to the smallest test MSE.

* Decomposition of MSE for given $x_0$
$$E\left(y_{0}-\hat{f}\left(x_{0}\right)\right)^{2}=\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)+\left[\operatorname{Bias}\left(\hat{f}\left(x_{0}\right)\right)\right]^{2}+\operatorname{Var}(\epsilon)$$
* To minimize $MSE$ *variance* and *bias* must be minized simultaneously.
* More flexible methods tend to have higher variance.

---
# 2.2.3 The classification setting
* Concepts for model accuracy can be transferred from the regression setting. 
* However, now the $y_i$ in $\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{n}, y_{n}\right)\right\}$ are categorical.
* Most common approach: Determine Average error rate
$$\frac{1}{n} \sum_{i=1}^{n} I\left(y_{i} \neq \hat{y}_{i}\right)$$
  + $\hat{y}_{i}$ predicted class label for *i*th observation.
  + $I\left(y_{i} \neq \hat{y}_{i}\right)$ *indicator variable* indicates whether $y_i$ is predicted correctly (0) or not (1)
  
---
## Bayes Classifier
* The error rate is minimized (for test data) on average by a classfier that assigns each observation to the most likely class, given its predictor values.
* That is, choose j such that
$$\operatorname{Pr}\left(Y=j | X=x_{0}\right)$$
is largest.
* However, if distribution of $Y$ given $X$ ist not know, Bayes classifier cannot be calculated.

---
### Example 7: Classification 
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 160}
include_graphics(path = "images/fig 2.13.png")
```
Fig 2.13 Simulated data set consisting of 100 observations in each of two groups, indicated in blue and in orange. Purple dashed line represents the Bayes decision boundary, i. e. where 
$\operatorname{Pr}(Y=1|(X_1, X_2) = \operatorname{Pr}(Y=1|(X_1, X_2)$ . Orange background grid indicates region in which a test observation will be assigned to the orange class, blue background grid indicates the region in which a test observation will be assigned to blue class.

Bayes error rate is given by $1-E\left(\max _{j} \operatorname{Pr}(Y=j | X)\right)$.

---
## K-Nearest neighbours
* Let K positive integer
* Choose the K point in training data set that are closest to point of interest $x_0$, denote these points by $\mathcal{N}_{0}$.
* Estimate $\operatorname{Pr}\left(Y=j | X=x_{0}\right)$ by
$$\operatorname{Pr}\left(Y=j | X=x_{0}\right)=\frac{1}{K} \sum_{i \in \mathcal{N}_{0}} I\left(y_{i}=j\right)$$
* Finally apply Bayes rule
* Choice of K affects KNN classifier drastically - see following graphs

---
### KNN classifier illustrated
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.14.png")
```
Fig 2.14 The KNN approach, using K = 3

---
### KNN with K=10
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.15.png")
```
Fig 2.14 The black curve indicates the KNN decision boundary on the
data from Figure 2.13, using K = 10. The Bayes decision boundary is shown as
a purple dashed line. The KNN and Bayes decision boundaries are very similar.

---
### KNN with K=1 and K=100
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 150}
include_graphics(path = "images/fig 2.16.png")
```
Fig 2.16 comparison of the KNN decision boundaries (solid black
curves) obtained using K = 1 and K = 100 on the data from Figure 2.13. With
K = 1, the decision boundary is overly flexible, while with K = 100 it is not
sufficiently flexible. The Bayes decision boundary is shown as a purple dashed
line.
---
### Test errors and training errors
```{r, echo = FALSE, eval = TRUE, include = TRUE, dpi = 170}
include_graphics(path = "images/fig 2.17.png")
```
Fig 2.17 KNN training error rate (blue, 200 observations) and test
error rate (orange, 5,000 observations) on the data from Figure 2.13, as the
level of flexibility (assessed using 1/K) increases, or equivalently as the number
of neighbors K decreases. The black dashed line indicates the Bayes error rate.
The jumpiness of the curves is due to the small size of the training data set.

---
class: middle, center

# Thanks!

